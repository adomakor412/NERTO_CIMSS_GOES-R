{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "large-stamp",
   "metadata": {},
   "source": [
    "# AI model for training (shark fin) artifacts on GOES-R\n",
    "\n",
    "[How to Train an Image Classifier in PyTorch and use it to Perform Basic Inference on Single Images](https://towardsdatascience.com/how-to-train-an-image-classifier-in-pytorch-and-use-it-to-perform-basic-inference-on-single-images-99465a1e9bf5)\n",
    "\n",
    "[TRAINING A CLASSIFIER](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "appreciated-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import os.path as op\n",
    "import os\n",
    "from subprocess import Popen\n",
    "import tensorboard\n",
    "import datetime\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# imports\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "induced-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed = 42\n",
    "data_train_dir = '/scratch/adomakor412/train/'\n",
    "data_test_dir = '/scratch/adomakor412/test/'\n",
    "data_val_dir = '/scratch/adomakor412/val/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-transfer",
   "metadata": {},
   "source": [
    "# Tensorboard command line set up\n",
    "\n",
    "#### [How to “reset” tensorboard data after killing tensorflow instance](https://stackoverflow.com/questions/34454721/how-to-reset-tensorboard-data-after-killing-tensorflow-instance)\n",
    "\n",
    "#### [Get started with TensorBoard](https://www.tensorflow.org/tensorboard/get_started)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "computational-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "stamp = datetime.datetime.now().strftime('%b-%d-%y:%H%M_%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "polar-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "particular-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "myTestData = []\n",
    "myTrainData = []\n",
    "myValData = []\n",
    "\n",
    "# def load_split_train_test(traindir, testdir, valdir):\n",
    "#     train_transforms = transforms.Compose([transforms.Resize(32),\n",
    "#                                        transforms.ToTensor(),\n",
    "#                                        ])\n",
    "#     test_transforms = transforms.Compose([transforms.Resize(32),\n",
    "#                                       transforms.ToTensor(),\n",
    "#                                       ])\n",
    "#     val_transforms = transforms.Compose([transforms.Resize(32),\n",
    "#                                       transforms.ToTensor(),\n",
    "#                                       ])\n",
    "\n",
    "#     train_data = datasets.ImageFolder(traindir,       \n",
    "#                     transform=train_transforms)\n",
    "#     test_data = datasets.ImageFolder(testdir,\n",
    "#                     transform=test_transforms)\n",
    "#     val_data = datasets.ImageFolder(valdir,\n",
    "#                     transform=test_transforms)\n",
    "    \n",
    "    \n",
    "#     trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size)\n",
    "#     testloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)\n",
    "#     valloader = torch.utils.data.DataLoader(val_data, batch_size=batch_size)\n",
    "    \n",
    "#     myTestData.append(test_data)\n",
    "#     myTrainData.append(train_data)\n",
    "#     myValData.append(val_data)\n",
    "    \n",
    "#     return trainloader, testloader, valloader\n",
    "def load_split_train_test(traindir, testdir, valdir):\n",
    "    train_transforms = transforms.Compose([transforms.Resize(32),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       ])\n",
    "    test_transforms = transforms.Compose([transforms.Resize(32),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      ])\n",
    "    val_transforms = transforms.Compose([transforms.Resize(32),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      ])\n",
    "\n",
    "    train_data = datasets.ImageFolder(traindir,       \n",
    "                    transform=train_transforms)\n",
    "    test_data = datasets.ImageFolder(testdir,\n",
    "                    transform=test_transforms)\n",
    "    val_data = datasets.ImageFolder(valdir,\n",
    "                    transform=test_transforms)\n",
    "    \n",
    "    \n",
    "    train_idx = nr.shuffle(list(range(len(traindir))))\n",
    "    test_idx = nr.shuffle(list(range(len(testdir))))\n",
    "    val_idx = nr.shuffle(list(range(len(valdir))))\n",
    "    \n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    val_sampler = SubsetRandomSampler(val_idx)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n",
    "    testloader = torch.utils.data.DataLoader(test_data, sampler = test_sampler, batch_size = batch_size)\n",
    "    valloader = torch.utils.data.DataLoader(val_data, sampler = val_sampler, batch_size = batch_size)\n",
    "    \n",
    "    myTestData.append(test_data)\n",
    "    myTrainData.append(train_data)\n",
    "    myValData.append(val_data)\n",
    "    \n",
    "    return trainloader, testloader, valloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "renewable-optics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fillin', 'sharkfin']\n"
     ]
    }
   ],
   "source": [
    "trainloader, testloader, valloader = load_split_train_test(data_train_dir,\n",
    "                                                           data_test_dir, \n",
    "                                                           data_val_dir)\n",
    "\n",
    "print(trainloader.dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "boolean-naples",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 1303\n",
       "    Root location: /scratch/adomakor412/test/\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=224, interpolation=PIL.Image.BILINEAR)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myTestData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "architectural-means",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dataset ImageFolder\n",
       "     Number of datapoints: 1455\n",
       "     Root location: /scratch/adomakor412/train/\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=224, interpolation=PIL.Image.BILINEAR)\n",
       "                ToTensor()\n",
       "            )]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myTrainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ruled-seattle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dataset ImageFolder\n",
       "     Number of datapoints: 553\n",
       "     Root location: /scratch/adomakor412/val/\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=224, interpolation=PIL.Image.BILINEAR)\n",
       "                ToTensor()\n",
       "            )]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myValData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "pretty-disposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('fillintrain.txt', 'r') as filehandle:\n",
    "#     for imgPath in filehandle:\n",
    "#         filehandle.write('%s\\n' % imgPath)\n",
    "       \n",
    "# with open('fillintest.txt', 'r') as filehandle:\n",
    "#     for imgPath in MyTestData:\n",
    "#         filehandle.write('%s\\n' % imgPath)\n",
    "        \n",
    "# with open('fillinval.txt', 'r') as filehandle:\n",
    "#     for imgPath in MyValData:\n",
    "#         filehandle.write('%s\\n' % imgPath)\n",
    "\n",
    "# with open('sharkfintrain.txt', 'r') as filehandle:\n",
    "#     for imgPath in MyTrainData:\n",
    "#         filehandle.write('%s\\n' % imgPath)\n",
    "      \n",
    "# with open('sharkfintest.txt', 'r') as filehandle:\n",
    "#     for imgPath in MyTestData:\n",
    "#         filehandle.write('%s\\n' % imgPath)\n",
    "        \n",
    "# with open('sharkfinval.txt', 'r') as filehandle:\n",
    "#     for imgPath in MyValData:\n",
    "#         filehandle.write('%s\\n' % imgPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "sophisticated-scanning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224]) 0\n"
     ]
    }
   ],
   "source": [
    "for data in trainloader.dataset:\n",
    "    print(data[0].shape, data[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fossil-holiday",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                                  else \"cpu\")\n",
    "model = models.resnet50(pretrained=True)\n",
    "# PATH = 'ResnetPretrained.pth'\n",
    "# model = torch.load(PATH)\n",
    "#torch.save(model, 'ResnetPretrained.pth');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "applicable-understanding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (4): LogSoftmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "model.fc = nn.Sequential(nn.Linear(2048, 512),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(512, 10),\n",
    "                                 nn.LogSoftmax(dim=1))\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "unnecessary-romantic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Epoch 1/10.. Train loss: 2.521.. Test loss: 1.156.. Test accuracy: 0.911\n",
      "2\n",
      "Epoch 1/10.. Train loss: 0.000.. Test loss: 2.225.. Test accuracy: 0.911\n",
      "3\n",
      "Epoch 1/10.. Train loss: 0.000.. Test loss: 3.242.. Test accuracy: 0.911\n",
      "4\n",
      "Epoch 1/10.. Train loss: 0.000.. Test loss: 4.231.. Test accuracy: 0.911\n",
      "5\n",
      "Epoch 1/10.. Train loss: 0.000.. Test loss: 5.166.. Test accuracy: 0.911\n",
      "6\n",
      "Epoch 1/10.. Train loss: 0.000.. Test loss: 6.122.. Test accuracy: 0.911\n",
      "7\n",
      "Epoch 1/10.. Train loss: 0.000.. Test loss: 7.060.. Test accuracy: 0.911\n",
      "8\n",
      "Epoch 1/10.. Train loss: 0.000.. Test loss: 7.974.. Test accuracy: 0.911\n",
      "9\n",
      "Epoch 1/10.. Train loss: 0.000.. Test loss: 8.906.. Test accuracy: 0.911\n",
      "10\n",
      "Epoch 1/10.. Train loss: 0.000.. Test loss: 9.866.. Test accuracy: 0.911\n",
      "11\n",
      "Epoch 1/10.. Train loss: 0.000.. Test loss: 10.708.. Test accuracy: 0.911\n",
      "12\n",
      "Epoch 1/10.. Train loss: 0.000.. Test loss: 11.292.. Test accuracy: 0.911\n",
      "13\n",
      "Epoch 1/10.. Train loss: 0.000.. Test loss: 11.893.. Test accuracy: 0.911\n",
      "14\n",
      "Epoch 1/10.. Train loss: 0.000.. Test loss: 12.436.. Test accuracy: 0.911\n",
      "15\n",
      "Epoch 1/10.. Train loss: 0.000.. Test loss: 13.074.. Test accuracy: 0.911\n",
      "16\n",
      "Epoch 1/10.. Train loss: 0.000.. Test loss: 13.621.. Test accuracy: 0.911\n",
      "17\n",
      "Epoch 1/10.. Train loss: 0.000.. Test loss: 14.042.. Test accuracy: 0.911\n",
      "18\n",
      "Epoch 1/10.. Train loss: 0.000.. Test loss: 14.441.. Test accuracy: 0.911\n",
      "19\n",
      "Epoch 1/10.. Train loss: 0.000.. Test loss: 14.829.. Test accuracy: 0.911\n",
      "20\n",
      "Epoch 1/10.. Train loss: 0.000.. Test loss: 15.201.. Test accuracy: 0.911\n",
      "21\n",
      "Epoch 1/10.. Train loss: 0.000.. Test loss: 15.509.. Test accuracy: 0.911\n",
      "22\n",
      "Epoch 1/10.. Train loss: 108.039.. Test loss: 13.185.. Test accuracy: 0.911\n",
      "23\n",
      "Epoch 1/10.. Train loss: 144.609.. Test loss: 10.312.. Test accuracy: 0.911\n"
     ]
    }
   ],
   "source": [
    "epochList = [1]#[1,10,20,30,40,50,60,70,80,90,100]\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 1#10\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "for epochRange in epochList:\n",
    "    for epoch in range(epochRange):\n",
    "        for inputs, labels in trainloader:\n",
    "            steps += 1\n",
    "            print(steps)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logps = model.forward(inputs)\n",
    "            loss = criterion(logps, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            #print('REACHED RUNNING LOSS')\n",
    "            if steps % print_every == 0:\n",
    "                #print('I am working')\n",
    "                test_loss = 0\n",
    "                accuracy = 0\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in testloader:\n",
    "                        inputs, labels = inputs.to(device),labels.to(device)\n",
    "                        logps = model.forward(inputs)\n",
    "                        batch_loss = criterion(logps, labels)\n",
    "                        test_loss += batch_loss.item()\n",
    "\n",
    "                        ps = torch.exp(logps)\n",
    "                        top_p, top_class = ps.topk(1, dim=1)\n",
    "                        equals = top_class == labels.view(*top_class.shape)\n",
    "                        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "                train_losses.append(running_loss/len(trainloader))\n",
    "                test_losses.append(test_loss/len(testloader))                    \n",
    "                print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                      f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                      f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                      f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "                running_loss = 0\n",
    "                model.train()\n",
    "        torch.save(model, f'model_epoch_{epoch}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "focused-harassment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 368
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.title(f'Loss function: step increments =23 \\n epochs = {epochList}')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "desirable-video",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "opposed-salad",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = trainloader\n",
    "testset = testloader\n",
    "\n",
    "classes = trainloader.dataset.classes\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\", vmin = 180, vmax = 300)\n",
    "        plt.grid(None) \n",
    "        plt.axis('off')\n",
    "        \n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)), vmin=180,vmax=300)\n",
    "        #plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        plt.grid(None) \n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "liable-milton",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # m input image channel, n output channels, rxr square convolution\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "#         super(Net, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 32, 5)\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "#         self.fc1 = nn.Linear(64*9*9, 1024)\n",
    "#         self.fc2 = nn.Linear(1024, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = x.view(x.size(0), -1)\n",
    "\n",
    "#         #x = x.view(-1, 64)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cloudy-mathematics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(batch_size, 3, 32, 32)\n",
    "out = net(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "protective-bargain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(batch_size, 3, 32, 32)\n",
    "out = net(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "false-arrest",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "relevant-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(f'logs/log{time.time()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "excessive-oasis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 1455\n",
       "    Root location: /scratch/adomakor412/train/\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=224, interpolation=PIL.Image.BILINEAR)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "successful-adelaide",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader._SingleProcessDataLoaderIter at 0x7fbdb910a6d8>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "relevant-subject",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-4abdc546fefe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get some random training images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# create grid of images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/adomakor412/conda/envs/MyEnv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/adomakor412/conda/envs/MyEnv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/adomakor412/conda/envs/MyEnv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/adomakor412/conda/envs/MyEnv/lib/python3.6/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/adomakor412/conda/envs/MyEnv/lib/python3.6/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandperm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid)#, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "# writer.add_image('four_fashion_mnist_images', img_grid)\n",
    "# try:\n",
    "#     writer.flush()\n",
    "# except:\n",
    "#     pass\n",
    "writer.add_image(f'log/GOES_images{time.time()}', img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "critical-chancellor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "incorporated-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    #print('OUTPUT\\n\\n', output)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    #print('PREDICTION \\n\\n', preds)\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(batch_size):\n",
    "        ax = fig.add_subplot(1, batch_size, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    fig.savefig(f'epoch_{epoch}-{stamp}.png')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bridal-fence",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [64 x 44944], m2: [400 x 120] at /tmp/pip-req-build-808afw3c/aten/src/TH/generic/THTensorMath.cpp:136",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-4a27a7de651e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/adomakor412/conda/envs/MyEnv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-124-b22b44841400>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# flatten all dimensions except batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/adomakor412/conda/envs/MyEnv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/adomakor412/conda/envs/MyEnv/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/adomakor412/conda/envs/MyEnv/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [64 x 44944], m2: [400 x 120] at /tmp/pip-req-build-808afw3c/aten/src/TH/generic/THTensorMath.cpp:136"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "    \n",
    "    if len(list(enumerate(trainloader, 0))) < 10:\n",
    "            print('Batch size too small (<10) for PR-curve')\n",
    "            \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        #print (data)\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # every 1000 mini-batches...\n",
    "#         if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            print('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_preds = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "        _, class_preds_batch = torch.max(output, 1)\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_preds.append(class_preds_batch)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_preds = torch.cat(class_preds)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_preds = test_preds == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_preds,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-timothy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
