{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "running-harvest",
   "metadata": {},
   "source": [
    "# Generate Full Disk images of GOES-R NetCDF files and upload them to GitLab database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-replication",
   "metadata": {},
   "source": [
    "https://gitlab.com/adomakor412/goes-r_fd_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "thrown-destiny",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radomako/.conda/envs/adomako/lib/python3.9/site-packages/pyresample/bilinear/__init__.py:50: UserWarning: XArray and/or zarr not found, XArrayBilinearResampler won't be available.\n",
      "  warnings.warn(\"XArray and/or zarr not found, XArrayBilinearResampler won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from netCDF4 import Dataset\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "\n",
    "from pyproj import Proj\n",
    "import pyproj\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from pyresample import image, geometry\n",
    "import sys\n",
    "import metpy\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "import os.path as op\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-intent",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "whole-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = Path('../goes-r_fd_image/')\n",
    "sharkfins_FD_NC = Path('~/scratch/gops/amqpfind/adomako_data/l1b_imagery_sharkfin/')\n",
    "caterpillar_FD_NC = Path('~/scratch/gops/amqpfind/adomako_data/l1b_imagery_caterpillar_track/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-liberal",
   "metadata": {},
   "source": [
    "## Functions for unfiltered cloud mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "radical-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rad2BT(rad, planck_fk1, planck_fk2, planck_bc1, planck_bc2):\n",
    "    \"\"\"Radiances to Brightness Temprature (using black body equation)\"\"\"\n",
    "    invRad = np.array(rad)**(-1)\n",
    "    arg = (invRad*planck_fk1) + 1.0\n",
    "    T = (- planck_bc1+(planck_fk2 * (np.log(arg)**(-1))) )*(1/planck_bc2) \n",
    "    return T\n",
    "\n",
    "def createUnfilteredPlotArray(ncFile,npFile,npPath):#Filtered Histrogram for cloud clear sky mask\n",
    "    Tmean= []\n",
    "    times = []\n",
    "    for ncf, npf in zip(ncFile, npFile):\n",
    "        imageBox = np.load(op.join(npPath,npf))\n",
    "        myFile = xr.open_dataset(op.join(ncPath,ncf))\n",
    "        planck_fk1 = float(myFile['planck_fk1'].data)\n",
    "        planck_fk2 = float(myFile['planck_fk2'].data) \n",
    "        planck_bc1 = float(myFile['planck_bc1'].data)                       \n",
    "        planck_bc2 = float(myFile['planck_bc2'].data)     \n",
    "        T = Rad2BT(imageBox.mean(), planck_fk1, planck_fk2, planck_bc1, planck_bc2)\n",
    "        tString = ncf[31:38]\n",
    "        times.append(tString)\n",
    "        Tmean.append(T)\n",
    "    return times, Tmean\n",
    "\n",
    "def listurls(prefix,html):\n",
    "    from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(html.text)\n",
    "    urllist = [elt['href'] for elt in soup.find_all(href=re.compile(prefix))]\n",
    "    return urllist\n",
    "\n",
    "def create_nc_Numpy(ncFile, pathOut):\n",
    "    myFile = xr.open_dataset(ncFile,engine=\"netcdf4\")\n",
    "    dat = myFile.metpy.parse_cf('Rad')#myFile['Rad']\n",
    "    geos = dat.metpy.cartopy_crs\n",
    "\n",
    "    cartopy_extent_goes = geos.x_limits + geos.y_limits\n",
    "    pyresample_extent_goes = (cartopy_extent_goes[0],\n",
    "                                cartopy_extent_goes[2],\n",
    "                                cartopy_extent_goes[1],\n",
    "                                cartopy_extent_goes[3])\n",
    "    goes_params = geos.proj4_params\n",
    "    rad = dat.data\n",
    "    \n",
    "    def normIm(im,gamma=1.0,reverse=False):\n",
    "        nim = ((im-np.nanmin(im))*(np.nanmax(im)-np.nanmin(im))**(-1))\n",
    "        if reverse:#want clouds to be white\n",
    "            nim = (1.0-nim**(gamma))\n",
    "        return nim\n",
    "    \n",
    "    def goes_2_roi(geos_crs, \n",
    "               target_extent,\n",
    "               target_rows,#actual length or base\n",
    "               target_cols,#actual width or height\n",
    "               cartopy_target_proj,\n",
    "               data_key='Rad',\n",
    "               radius_of_influence=50000):\n",
    "        \"\"\"Function that goes from loaded GOES data to data resampled in a projection for an extent\"\"\"\n",
    "        cartopy_source_extent = geos_crs.x_limits + geos_crs.y_limits\n",
    "        pyresample_source_extent = (cartopy_source_extent[0],\n",
    "                                    cartopy_source_extent[2],\n",
    "                                    cartopy_source_extent[1],\n",
    "                                    cartopy_source_extent[3])\n",
    "        rad = dat.data\n",
    "        source_area = geometry.AreaDefinition('GOES-1X', 'Full Disk','GOES-1X', \n",
    "                                              geos_crs.proj4_params,\n",
    "                                              rad.shape[1], rad.shape[0],\n",
    "                                              pyresample_source_extent)\n",
    "        area_target_def = geometry.AreaDefinition('areaTest', 'Target Region', 'areaTest',\n",
    "                                            cartopy_target_proj.proj4_params,\n",
    "                                            target_rows, target_cols,\n",
    "                                            target_extent)\n",
    "        #Read up on recommend class \n",
    "        #https://pyresample.readthedocs.io/en/latest/search.html?q=Numpy+Resampler+Bilinear&check_keywords\n",
    "        \n",
    "        #can suppress warning for long runs as to not generate an overload on the browser rendering .ipynb\n",
    "        geos_con_nn = image.ImageContainerNearest(rad, \n",
    "                                                source_area, \n",
    "                                                radius_of_influence=radius_of_influence)\n",
    "\n",
    "        # Here we are using pyresample for the remapping\n",
    "        area_proj_con_nn = geos_con_nn.resample(area_target_def)\n",
    "        return area_proj_con_nn.image_data\n",
    "        \n",
    "    def cartopy_pyresample_toggle_extent(input_extent):\n",
    "        return np.array(input_extent)[np.array([0,2,1,3])]\n",
    "\n",
    "    def transform_cartopy_extent(source_extent,source_proj, target_proj):\n",
    "        target_extent = target_proj.transform_points(source_proj, \n",
    "                                                     np.array(source_extent[:2]),\n",
    "                                                     np.array(source_extent[2:])).ravel()\n",
    "        # target_extent in 3D, must be in 2D\n",
    "        return cartopy_pyresample_toggle_extent(np.array(target_extent)[np.array([0,1,3,4])])\n",
    "    pc = ccrs.PlateCarree()\n",
    "    mc = ccrs.Mercator()\n",
    "\n",
    "    # Convert extent from pc to mc (both cylindrical projections)\n",
    "    extent_pc = [-109.59326, -102.40674, 8.94659, -8.94656]\n",
    "    \n",
    "    target_extent_mc_cartopy = transform_cartopy_extent(extent_pc, pc, mc)\n",
    "    target_extent_mc_pyresample = cartopy_pyresample_toggle_extent(target_extent_mc_cartopy)\n",
    "    \n",
    "    roi_rads = goes_2_roi(geos,\n",
    "               target_extent_mc_pyresample,\n",
    "               401,1001,\n",
    "               mc)\n",
    "    ####\n",
    "    full_filename = op.join(pathOut,ncFile[:-3])\n",
    "    np.save(full_filename,roi_rads)\n",
    "    myFile.close()\n",
    "    return\n",
    "\n",
    "def download(url,toPath, saveName):\n",
    "    cmd = [ 'wget ' + url +' -P ' + toPath +' -O '+ saveName]#if re.search('C07',url)\n",
    "    print(cmd)\n",
    "    pid = Popen(cmd, shell=True)\n",
    "    pid.communicate()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-jurisdiction",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "divine-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sat = [16]\n",
    "band = range(7,17)\n",
    "year = [2021]\n",
    "month = [2]\n",
    "day = list(range(1,32))\n",
    "hour = list(range(1,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "prostate-smith",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = list(itertools.product(Sat,\\\n",
    "        band,\\\n",
    "        year,\\\n",
    "        month,\\\n",
    "        day,\\\n",
    "        hour))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abandoned-prevention",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'raw.gitlab.com/-/ide/project/adomakor412/goes-r_fd_image/tree/master/-/artifacts.csv/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-c8f9b7d159dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#data = pd.read_csv('https://raw.githubusercontent.com/adomakor412/GOEScode/master/G17series.csv'\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#,error_bad_lines=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'raw.'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mCSV_URL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/adomako/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/adomako/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/adomako/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/adomako/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1043\u001b[0m             )\n\u001b[1;32m   1044\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/adomako/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1863\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/adomako/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \"\"\"\n\u001b[0;32m-> 1357\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1358\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/adomako/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'raw.gitlab.com/-/ide/project/adomakor412/goes-r_fd_image/tree/master/-/artifacts.csv/'"
     ]
    }
   ],
   "source": [
    "CSV_URL = 'gitlab.com/-/ide/project/adomakor412/goes-r_fd_image/tree/master/-/artifacts.csv/'\n",
    "#data = pd.read_csv('https://raw.githubusercontent.com/adomakor412/GOEScode/master/G17series.csv'\\\n",
    "#,error_bad_lines=False)\n",
    "data = pd.read_csv('raw.'+CSV_URL)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Set HDF5 locking to false. \n",
    "Netcdf package uses hdf under the hood and the package has been updated.\n",
    "Now you need to explicitly set locking to false, otherwise you won't be able to overwrite .nc (.npy?) files\n",
    "'''\n",
    "#export HDF5_USE_FILE_LOCKING=FALSE\n",
    "#export lock=false\n",
    "\n",
    "bins = np.linspace(195,255,255-195)\n",
    "filelog = open('log_Histogram.txt','w')\n",
    "\n",
    "\n",
    "#check for GOES-16 and GOES-17 and plot what is available\n",
    "for SS, bb, yyyy, mm, dd, hr in search:\n",
    "    SS, bb, yyyy, mm, dd, hr = \\\n",
    "        str(SS).zfill(2),\\\n",
    "        str(bb).zfill(2),\\\n",
    "        str(yyyy).zfill(4),\\\n",
    "        str(mm).zfill(2),\\\n",
    "        str(dd).zfill(2),\\\n",
    "        str(hr).zfill(2)\n",
    "    \n",
    "    templateURL16 = f'http://home.chpc.utah.edu/~u0553130/Brian_Blaylock/cgi-bin/'\\\n",
    "        + f'goes16_download.cgi?source=aws&satellite='\\\n",
    "        + f'noaa-goes{SS}&domain=F&product=ABI-L1b-Rad&date={yyyy}-{mm}-{dd}&hour={hr}'\n",
    "\n",
    "    SS = '17'\n",
    "    templateURL17 = f'http://home.chpc.utah.edu/~u0553130/Brian_Blaylock/cgi-bin/'\\\n",
    "        + f'goes16_download.cgi?source=aws&satellite='\\\n",
    "        + f'noaa-goes{SS}&domain=F&product=ABI-L1b-Rad&date={yyyy}-{mm}-{dd}&hour={hr}'\n",
    "    \n",
    "    calDate = gregorian.date(int(yyyy), int(mm), int(dd))\n",
    "    DDD = ordinal.from_gregorian(calDate.year, calDate.month, calDate.day)[1]\n",
    "    \n",
    "    #os.path.isfile() returs explicit T/F but doesn't support wild cards\n",
    "    #glob.glob returns a list where [] is read as a False condition in python\n",
    "    cond1=glob.glob(f'{storage}/{yyyy}/GOES-R_panel_GOES16vsGOES17_FD_{yyyy}{DDD}_{hr}*_Band{bb}.png')\n",
    "    if len(cond1)!=6:\n",
    "        '''Get URLS for download'''\n",
    "        req16 = requests.get(templateURL16)\n",
    "        req17 = requests.get(templateURL17)\n",
    "\n",
    "        if yyyy == '2018':\n",
    "            product = '3'\n",
    "        else:\n",
    "            product = '6'\n",
    "        prefix = f\"OR_ABI-L1b-RadF-M{product}C\" + bb\n",
    "        prefix.format(**{'product':product})\n",
    "        bandURLList16 = listurls(prefix,req16)#list of strings using beautiful soup\n",
    "        bandURLList17 = listurls(prefix,req17)\n",
    "        bandURLList16.sort()\n",
    "        bandURLList17.sort()\n",
    "\n",
    "        cnt = 0 #keep a counter to avoid crossing FD with similar file names and performance\n",
    "        '''iterate over pairs of GOES NETCDF, download, and convert to numpy'''\n",
    "        #print(list(enumerate(bandURLList16)))\n",
    "        for FD16 in bandURLList16: #Last string chars are of this format: c20192220009464.nc   \n",
    "            print(FD16, file=filelog)\n",
    "\n",
    "            #YYYY = FD16[-17:-13]\n",
    "            DDD = FD16[-13:-10]\n",
    "            HH = FD16[-10:-8]\n",
    "            i = FD16.find('_s')\n",
    "            MM = FD16[i+11: i+13]\n",
    "            ss = FD16[i+13: i+15]\n",
    "            #print(f'{YYYY}{DDD}{HH}{MM}')\n",
    "\n",
    "            _FD17 = None\n",
    "            for FD17 in bandURLList17[cnt:i]:\n",
    "                if FD16[i:13] == FD17[i:13]:\n",
    "                    cnt +=1\n",
    "                    _FD17 = FD17\n",
    "                    download17 = requests.get(FD17)\n",
    "                    nc17 = open('nc17.nc','wb')#open('nc17.nc','wb')\n",
    "                    nc17.write(download17.content)\n",
    "                    nc17.close()\n",
    "                    myFile_17 = xr.open_dataset('nc17.nc')\n",
    "                    npy17 = create_nc_Numpy('nc17.nc', '')\n",
    "\n",
    "                    '''Load numpy files'''\n",
    "                    imageBox_17 = np.load('nc17.npy')\n",
    "                    planck_fk1_17 = float(myFile_17['planck_fk1'].data)\n",
    "                    planck_fk2_17 = float(myFile_17['planck_fk2'].data) \n",
    "                    planck_bc1_17 = float(myFile_17['planck_bc1'].data)                       \n",
    "                    planck_bc2_17 = float(myFile_17['planck_bc2'].data)\n",
    "                    myFile_17.close()\n",
    "                    break\n",
    "                else:\n",
    "                    _FD17 = None\n",
    "                    imageBox_17 = None\n",
    "                    planck_fk1_17 = None\n",
    "                    planck_fk2_17 = None\n",
    "                    planck_bc1_17 = None\n",
    "                    planck_bc2_17 = None\n",
    "            download16 = requests.get(FD16)\n",
    "            nc16 = open('nc16.nc','wb')#open('nc16.nc','wb')\n",
    "            nc16.write(download16.content)\n",
    "            nc16.close()\n",
    "            npy16 = create_nc_Numpy('nc16.nc', '')\n",
    "\n",
    "            '''Load numpy files'''\n",
    "            imageBox_16 = np.load('nc16.npy')\n",
    "            myFile_16 = xr.open_dataset('nc16.nc')\n",
    "            planck_fk1_16 = float(myFile_16['planck_fk1'].data)\n",
    "            planck_fk2_16 = float(myFile_16['planck_fk2'].data) \n",
    "            planck_bc1_16 = float(myFile_16['planck_bc1'].data)                       \n",
    "            planck_bc2_16 = float(myFile_16['planck_bc2'].data)\n",
    "            myFile_16.close()\n",
    "\n",
    "            '''Create subplot figures and save'''\n",
    "            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(15,15))\n",
    "\n",
    "            '''Histograms'''\n",
    "            ax1.set_title(f'GOES-16 ABI Band {bb} (6.2µm) {mm}-{dd}-{yyyy} {HH}:{MM} UTC')\n",
    "            ax1.set_ylabel('density')#,fontsize = 16)\n",
    "            ax1.set_xlabel('Temperature (K)')#, fontsize = 16)\n",
    "            Tbox16 = Rad2BT(imageBox_16, planck_fk1_16, planck_fk2_16, planck_bc1_16, planck_bc2_16)\n",
    "            ax1.hist(Tbox16.ravel(), bins = bins, density = True, label = 'Temp dist.')       \n",
    "            ax1.yaxis.set_major_formatter(PercentFormatter(1))\n",
    "            ax1.axvline(Tbox16.mean(), color='r',label = 'NOAA avg.')\n",
    "            ax1.legend(loc='upper left')\n",
    "            ax1.axis(ymin=0, ymax=0.25)# Check July 15, 2020, 197th day of the year       \n",
    "\n",
    "            if None != _FD17:\n",
    "                ax2.set_title(f'GOES-17 ABI Band {bb} (6.2µm) {mm}-{dd}-{yyyy} {HH}:{MM} UTC')\n",
    "                ax2.set_ylabel('density')#,fontsize = 16)\n",
    "                ax2.set_xlabel('Temperature (K)')#, fontsize = 16)\n",
    "                Tbox17 = Rad2BT(imageBox_17, planck_fk1_17, planck_fk2_17, planck_bc1_17, planck_bc2_17)\n",
    "                ax2.hist(Tbox17.ravel(), bins = bins, density = True, label = 'Temp dist.')\n",
    "                ax2.yaxis.set_major_formatter(PercentFormatter(1))\n",
    "                ax2.axvline(Tbox17.mean(), color='r',label = 'NOAA avg.')\n",
    "                ax2.legend(loc='upper left')\n",
    "                ax2.axis(ymin=0, ymax=0.25)# Check July 15, 2020, 197th day of the year\n",
    "\n",
    "                rc = np.vstack([Tbox16.ravel(), Tbox17.ravel()])\n",
    "                XY = rc[:,np.isfinite(rc).all(axis=0)]\n",
    "                G16 = XY[0]\n",
    "                G17 = XY[1]\n",
    "                plabels = ['0%', '25%', '50%', '75%', '100%']\n",
    "\n",
    "                f'''Empirical CDF {mm}-{dd}-{yyyy} {HH}:{MM} UTC'''\n",
    "                xticks = np.arange(len(G17))\n",
    "                xticks = [st.scoreatpercentile(xticks, p) for p in [0, 25, 50, 75, 100]]\n",
    "                ax3.plot(sorted(G17), label='G17',linewidth=None, alpha=0.5)\n",
    "                ax3.plot(sorted(G16), label='G16',linewidth=None, alpha=0.5)\n",
    "                ax3.legend(loc = 'upper left')\n",
    "                ax3.set_title(f'Empirical CDF for {dd}-{mm}-{yyyy}')\n",
    "                ax3.set_xticks(xticks)\n",
    "                ax3.set_xticklabels(plabels)\n",
    "                ax3.set_xlabel('quantiles')\n",
    "                ax3.set_ylabel('Temperature (K)')\n",
    "                ax3.axis(ymin=195, ymax=255)\n",
    "\n",
    "                '''Area Under Curve (AUC)'''\n",
    "                xRange = round(255-195)# Check July 15, 2020, 197th day of the year\n",
    "                _G17 = np.linspace(G17.min(), G17.max(), xRange)\n",
    "                _G17n = (_G17 - min(_G17))/(max(_G17) - min(_G17))\n",
    "\n",
    "    #             _G16 = np.linspace(G16.min(), G16.max(), xRange)\n",
    "    #             _G16n = (_G16 - min(_G16))/(max(_G16) - min(_G16))\n",
    "                _G16 = [st.scoreatpercentile(G16, st.percentileofscore(G17,g17s,\n",
    "                    kind='strict')) for g17s in _G17]\n",
    "\n",
    "                _G16n = (_G16 - min(_G16))/(max(_G16) - min(_G16))\n",
    "\n",
    "                #y = f(x) is normalized and dx is represented by 1/xRange–a factorable constant interval\n",
    "                AUC = round(sum(_G16n)/xRange,4)#Area under curve is sum of y * dx\n",
    "\n",
    "                ax4.plot(_G16n, _G17n, label=f\"AUC: {AUC}\")\n",
    "                ax4.legend(loc = 'upper left')\n",
    "                ax4.set_ylabel('G16')\n",
    "                ax4.set_xlabel('G17')\n",
    "                ax4.set_title('Transform of G17 to G16')\n",
    "                ax4.set_aspect('equal')\n",
    "                SoF = 1-2*abs(0.5-AUC)\n",
    "                ax4.text(0, 0.75, f'Straightness of Fit \\n (SoF): {round(100*SoF,2)}%', style='italic',\n",
    "                bbox={'alpha': 0.5, 'pad': 10})\n",
    "\n",
    "            fig.suptitle('Ronald O.S. Adomako, City College of New York, NOAA-CESSRST', fontsize=12)\n",
    "            cond2 = os.path.isfile(f'{storage}/{yyyy}')\n",
    "\n",
    "            if not cond2:\n",
    "                #KEEP CONDITION AS A DYNAMIC F-STRING OTHERWISE VARIABLE IS STATIC, utilize loop\n",
    "                #make directory per year\n",
    "                cmd = [f'mkdir {storage}/{yyyy}']\n",
    "                pid = Popen(cmd, shell=True) \n",
    "                pid.communicate()\n",
    "\n",
    "            fig.savefig(op.join(storage,f\"{yyyy}/GOES-R_panel_GOES16vsGOES17_FD_{yyyy}{DDD}_{HH}{MM}{ss}_Band{bb}.png\"))\n",
    "filelog.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
