{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "running-harvest",
   "metadata": {},
   "source": [
    "# Generate Full Disk images of GOES-R NetCDF files and upload them to GitLab database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-replication",
   "metadata": {},
   "source": [
    "https://gitlab.com/adomakor412/goes-r_fd_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "thrown-destiny",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radomako/.conda/envs/adomako/lib/python3.9/site-packages/pyresample/bilinear/__init__.py:50: UserWarning: XArray and/or zarr not found, XArrayBilinearResampler won't be available.\n",
      "  warnings.warn(\"XArray and/or zarr not found, XArrayBilinearResampler won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from netCDF4 import Dataset\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from pathlib import Path\n",
    "from subprocess import Popen\n",
    "import itertools\n",
    "\n",
    "from pyproj import Proj\n",
    "import pyproj\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from pyresample import image, geometry\n",
    "import sys\n",
    "import metpy\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "import os.path as op\n",
    "import glob\n",
    "from convertdate import gregorian, ordinal\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-intent",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "whole-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storage = Path('../goes-r_fd_image/')\n",
    "# sharkfins_FD_NC = Path('~/scratch/gops/amqpfind/adomako_data/l1b_imagery_sharkfin/')\n",
    "# caterpillar_FD_NC = Path('~/scratch/gops/amqpfind/adomako_data/l1b_imagery_caterpillar_track/')\n",
    "storage = '../goes-r_fd_image/'\n",
    "sharkfins_FD_NC = '~/scratch/gops/amqpfind/adomako_data/l1b_imagery_sharkfin/'\n",
    "caterpillar_FD_NC = '~/scratch/gops/amqpfind/adomako_data/l1b_imagery_caterpillar_track/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-financing",
   "metadata": {},
   "source": [
    "## Functions for unfiltered cloud mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "choice-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rad2BT(rad, planck_fk1, planck_fk2, planck_bc1, planck_bc2):\n",
    "    \"\"\"Radiances to Brightness Temprature (using black body equation)\"\"\"\n",
    "    \n",
    "    planck_fk1 = abs(planck_fk1)\n",
    "    planck_fk2 = abs(planck_fk2)\n",
    "    planck_bc1 = abs(planck_bc1)\n",
    "    planck_bc2 = abs(planck_bc2)\n",
    "    \n",
    "    invRad = np.array(abs(rad))**(-1)\n",
    "    arg = (invRad*planck_fk1) + 1.0\n",
    "    T = (- planck_bc1+(planck_fk2 * (np.log(arg)**(-1))) )*(1/planck_bc2)\n",
    "    return T\n",
    "\n",
    "def createUnfilteredPlotArray(ncFile,npFile,npPath):#Filtered Histrogram for cloud clear sky mask\n",
    "    Tmean= []\n",
    "    times = []\n",
    "    for ncf, npf in zip(ncFile, npFile):\n",
    "        imageBox = np.load(op.join(npPath,npf))\n",
    "        myFile = xr.open_dataset(op.join(ncPath,ncf))\n",
    "        planck_fk1 = float(myFile['planck_fk1'].data)\n",
    "        planck_fk2 = float(myFile['planck_fk2'].data) \n",
    "        planck_bc1 = float(myFile['planck_bc1'].data)                       \n",
    "        planck_bc2 = float(myFile['planck_bc2'].data)     \n",
    "        T = Rad2BT(imageBox.mean(), planck_fk1, planck_fk2, planck_bc1, planck_bc2)\n",
    "        tString = ncf[31:38]\n",
    "        times.append(tString)\n",
    "        Tmean.append(T)\n",
    "    return times, Tmean\n",
    "\n",
    "def listurls(prefix,html):\n",
    "    from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(html.text)\n",
    "    urllist = [elt['href'] for elt in soup.find_all(href=re.compile(prefix))]\n",
    "    return urllist\n",
    "\n",
    "def create_nc_Numpy(ncFile, pathOut):\n",
    "    myFile = xr.open_dataset(ncFile,engine=\"netcdf4\")\n",
    "    dat = myFile.metpy.parse_cf('Rad')#myFile['Rad']\n",
    "    geos = dat.metpy.cartopy_crs\n",
    "\n",
    "    cartopy_extent_goes = geos.x_limits + geos.y_limits\n",
    "    pyresample_extent_goes = (cartopy_extent_goes[0],\n",
    "                                cartopy_extent_goes[2],\n",
    "                                cartopy_extent_goes[1],\n",
    "                                cartopy_extent_goes[3])\n",
    "    goes_params = geos.proj4_params\n",
    "    rad = dat.data\n",
    "    \n",
    "    def normIm(im,gamma=1.0,reverse=False):\n",
    "        nim = ((im-np.nanmin(im))*(np.nanmax(im)-np.nanmin(im))**(-1))\n",
    "        if reverse:#want clouds to be white\n",
    "            nim = (1.0-nim**(gamma))\n",
    "        return nim\n",
    "    \n",
    "    def goes_2_roi(geos_crs, \n",
    "               target_extent,\n",
    "               target_rows,#actual length or base\n",
    "               target_cols,#actual width or height\n",
    "               cartopy_target_proj,\n",
    "               data_key='Rad',\n",
    "               radius_of_influence=50000):\n",
    "        \"\"\"Function that goes from loaded GOES data to data resampled in a projection for an extent\"\"\"\n",
    "        cartopy_source_extent = geos_crs.x_limits + geos_crs.y_limits\n",
    "        pyresample_source_extent = (cartopy_source_extent[0],\n",
    "                                    cartopy_source_extent[2],\n",
    "                                    cartopy_source_extent[1],\n",
    "                                    cartopy_source_extent[3])\n",
    "        rad = dat.data\n",
    "        source_area = geometry.AreaDefinition('GOES-1X', 'Full Disk','GOES-1X', \n",
    "                                              geos_crs.proj4_params,\n",
    "                                              rad.shape[1], rad.shape[0],\n",
    "                                              pyresample_source_extent)\n",
    "        area_target_def = geometry.AreaDefinition('areaTest', 'Target Region', 'areaTest',\n",
    "                                            cartopy_target_proj.proj4_params,\n",
    "                                            target_rows, target_cols,\n",
    "                                            target_extent)\n",
    "        #Read up on recommend class \n",
    "        #https://pyresample.readthedocs.io/en/latest/search.html?q=Numpy+Resampler+Bilinear&check_keywords\n",
    "        \n",
    "        #can suppress warning for long runs as to not generate an overload on the browser rendering .ipynb\n",
    "        geos_con_nn = image.ImageContainerNearest(rad, \n",
    "                                                source_area, \n",
    "                                                radius_of_influence=radius_of_influence)\n",
    "\n",
    "        # Here we are using pyresample for the remapping\n",
    "        area_proj_con_nn = geos_con_nn.resample(area_target_def)\n",
    "        return area_proj_con_nn.image_data\n",
    "        \n",
    "    def cartopy_pyresample_toggle_extent(input_extent):\n",
    "        return np.array(input_extent)[np.array([0,2,1,3])]\n",
    "\n",
    "    def transform_cartopy_extent(source_extent,source_proj, target_proj):\n",
    "        target_extent = target_proj.transform_points(source_proj, \n",
    "                                                     np.array(source_extent[:2]),\n",
    "                                                     np.array(source_extent[2:])).ravel()\n",
    "        # target_extent in 3D, must be in 2D\n",
    "        return cartopy_pyresample_toggle_extent(np.array(target_extent)[np.array([0,1,3,4])])\n",
    "    pc = ccrs.PlateCarree()\n",
    "    mc = ccrs.Mercator()\n",
    "\n",
    "    # Convert extent from pc to mc (both cylindrical projections)\n",
    "    extent_pc = [-109.59326, -102.40674, 8.94659, -8.94656]\n",
    "    \n",
    "    target_extent_mc_cartopy = transform_cartopy_extent(extent_pc, pc, mc)\n",
    "    target_extent_mc_pyresample = cartopy_pyresample_toggle_extent(target_extent_mc_cartopy)\n",
    "    \n",
    "    roi_rads = goes_2_roi(geos,\n",
    "               target_extent_mc_pyresample,\n",
    "               401,1001,\n",
    "               mc)\n",
    "    ####\n",
    "    full_filename = op.join(pathOut,ncFile[:-3])\n",
    "    np.save(full_filename,roi_rads)\n",
    "    myFile.close()\n",
    "    return\n",
    "\n",
    "def download(url,toPath, saveName):\n",
    "    cmd = [ 'wget ' + url +' -P ' + toPath +' -O '+ saveName]#if re.search('C07',url)\n",
    "    #print(cmd)\n",
    "    pid = Popen(cmd, shell=True)\n",
    "    pid.communicate()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-charleston",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prescribed-banks",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sat = [16,17]\n",
    "band = range(7,17)\n",
    "year = [2021]\n",
    "month = list(range(1,3))\n",
    "day = list(range(1,32))\n",
    "hour = list(range(1,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "weird-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = list(itertools.product(Sat,\\\n",
    "        band,\\\n",
    "        year,\\\n",
    "        month,\\\n",
    "        day,\\\n",
    "        hour))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-witness",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "stupid-migration",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def execute(chunk, band):\n",
    "    filelog = open('log_FD_image.txt','w')\n",
    "\n",
    "    #for SS, bb, yyyy, mm, dd, hr in chunk:\n",
    "    SS, bb, yyyy, mm, dd, hr = chunk\n",
    "    bb = band\n",
    "    SS, bb, yyyy, mm, dd, hr = \\\n",
    "        str(SS).zfill(2),\\\n",
    "        str(bb).zfill(2),\\\n",
    "        str(yyyy).zfill(4),\\\n",
    "        str(mm).zfill(2),\\\n",
    "        str(dd).zfill(2),\\\n",
    "        str(hr).zfill(2)\n",
    "\n",
    "    calDate = gregorian.date(int(yyyy), int(mm), int(dd))\n",
    "    DDD = ordinal.from_gregorian(calDate.year, calDate.month, calDate.day)[1]\n",
    "    DDD = str(DDD).zfill(3)\n",
    "\n",
    "    #Create Directories    \n",
    "    cond2 = os.path.exists(f'{storage}/{yyyy}')\n",
    "    cond3 = os.path.exists(f'{storage}/{yyyy}/{DDD}')\n",
    "    cond4 = os.path.exists(f'{storage}/{yyyy}/{DDD}/{bb}')\n",
    "\n",
    "    if not cond2:\n",
    "        #KEEP CONDITION AS A DYNAMIC F-STRING OTHERWISE VARIABLE IS STATIC, utilize loop\n",
    "        #make di\n",
    "            #Create Directoriesrectory per year\n",
    "        cmd = [f'mkdir {storage}/{yyyy}']\n",
    "        pid = Popen(cmd, shell=True) \n",
    "        pid.communicate()\n",
    "\n",
    "    if not cond3:\n",
    "        #KEEP CONDITION AS A DYNAMIC F-STRING OTHERWISE VARIABLE IS STATIC, utilize loop\n",
    "        #make directory per year\n",
    "        cmd = [f'mkdir {storage}/{yyyy}/{DDD}']\n",
    "        pid = Popen(cmd, shell=True) \n",
    "        pid.communicate()\n",
    "        \n",
    "    if not cond4:\n",
    "        #KEEP CONDITION AS A DYNAMIC F-STRING OTHERWISE VARIABLE IS STATIC, utilize loop\n",
    "        #make directory per year\n",
    "        cmd = [f'mkdir {storage}/{yyyy}/{DDD}/{bb}']\n",
    "        pid = Popen(cmd, shell=True) \n",
    "        pid.communicate()\n",
    "\n",
    "    try:\n",
    "\n",
    "\n",
    "        #Not a cd command, use absolute path\n",
    "        #netcdf = glob.glob(f'~/arcdata/goes/grb/goes{SS}/{yyyy}/{yyyy}_{mm}_{dd}_{DDD}/abi/L1b/RadF/')\n",
    "        netcdf = glob.glob(f'/arcdata/goes/grb/goes{SS}/{yyyy}/{yyyy}_{mm}_{dd}_{DDD}/abi/L1b/RadF/*')\n",
    "#         print(yyyy,mm,dd,DDD)\n",
    "#         print(netcdf)\n",
    "#         print(len(netcdf))\n",
    "#         break\n",
    "        print(netcdf, file=filelog)\n",
    "\n",
    "        for file in netcdf:\n",
    "            print(file)\n",
    "            i = file.find('_s')#+2\n",
    "            HH = file[i+9: i+11]\n",
    "            MM = file[i+11: i+13]\n",
    "            ss = file[i+13: i+15]\n",
    "\n",
    "            '''\n",
    "            https://stackoverflow.com/questions/13714454/specifying-and-saving-a-figure-with-exact-size-in-pixels\n",
    "            '''\n",
    "            my_dpi = 192\n",
    "            resolution = 5424\n",
    "\n",
    "            GOES_R = xr.open_dataset(file)\n",
    "            GOES_image = GOES_R['Rad']\n",
    "\n",
    "\n",
    "            planck_fk1 = float(GOES_R['planck_fk1'].data)\n",
    "            planck_fk2 = float(GOES_R['planck_fk2'].data) \n",
    "            planck_bc1 = float(GOES_R['planck_bc1'].data)                       \n",
    "            planck_bc2 = float(GOES_R['planck_bc2'].data)\n",
    "            #Need not convert projection: using full image, no pyproj interpolation of region of interest\n",
    "            Kelvin_GOES_image = Rad2BT(GOES_image, planck_fk1, planck_fk2, planck_bc1, planck_bc2)\n",
    "\n",
    "            #Call pixelage before rendering\n",
    "            plt.figure(figsize=(resolution/my_dpi, resolution/my_dpi), dpi=my_dpi)\n",
    "\n",
    "            fig1 = plt.imshow(Kelvin_GOES_image, interpolation='none', vmin = 180, vmax = 300)\n",
    "            plt.grid(None)\n",
    "            plt.axis('off')\n",
    "            #fig1=plt.imshow(Kelvin_GOES_image,cmap='Greys',interpolation='none',vmin=180,vmax=300)\n",
    "\n",
    "            #print('ERROR IS NOT HERE')\n",
    "            \n",
    "            naming = f'{yyyy}/{DDD}/{bb}/FD_goes{SS}_B{bb}_{yyyy}-{mm}-{dd}_{DDD}_{HH}{MM}{ss}'\\\n",
    "                + 'UTC_5424x5424_plain.png'\n",
    "            \n",
    "            if not os.path.isfile(op.join(storage,naming)):\n",
    "                plt.grid(None)\n",
    "                fig1.figure.savefig( op.join(storage,naming) )\n",
    "            \n",
    "            #print('ERROR IS NOT HERE')\n",
    "            \n",
    "            #fig1 = plt.imshow(GOES_image)\n",
    "            plt.clim(180,300)#Kelvin\n",
    "            cbar = plt.colorbar(fraction=0.1)\n",
    "            cbar.ax.set_ylabel('Kelvin')\n",
    "            plt.grid(None) #Call after the imshow, redraws\n",
    "            plt.axis('off')#Call after the imshow, redraws; \"layer\" to previous drawing\n",
    "\n",
    "            title = f'Brightness Temperature in Kelvin \\n Full Disk GOES-{SS} Image Band{bb}'\n",
    "            ttl = plt.title(f\"{title}\\n Date {mm}-{dd}, Year {yyyy}, \\n Day {DDD}, Time {HH}:{MM}:{ss}\",\\\n",
    "                       fontsize=\"x-large\", fontweight='bold', pad = 6.0)\n",
    "            ttl.set_position([.5, 1.05])\n",
    "\n",
    "            naming = f'{yyyy}/{DDD}/{bb}/FD_goes{SS}_B{bb}_{yyyy}-{mm}-{dd}_{DDD}_{HH}{MM}{ss}UTC_5424x5424.png'\n",
    "            if not os.path.isfile(op.join(storage,naming)):\n",
    "                fig1.figure.savefig(op.join(storage,naming))\n",
    "\n",
    "            plt.close('all')\n",
    "            GOES_R.close()\n",
    "\n",
    "    except ValueError as e:\n",
    "        print('THERE IS AN ERROR')\n",
    "        print('\\n', file = filelog)\n",
    "        print(file, file = filelog)\n",
    "        print(e, file = filelog)\n",
    "        print('\\n', file = filelog)\n",
    "\n",
    "    filelog.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "#agents = 5\n",
    "#chunksize = 3\n",
    "\n",
    "agents = 3\n",
    "#Do bands\n",
    "# use number of bands as agents\n",
    "with Pool(processes=agents) as pool:\n",
    "    #pool.map(execute, search, chunksize=None)\n",
    "    pool.map(execute, search)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
