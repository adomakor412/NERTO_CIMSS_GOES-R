{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram of GOES-16, GOES-17, Empirical CDF, and AUC for Full disk samples in region of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import itertools\n",
    "import pandas as pd\n",
    "# npPath = '/sharedData/scratch/all_npy3/'\n",
    "# ncPath = '/sharedData/scratch/april_data/'\n",
    "# acmPath = '/sharedData/scratch/all_npy3/'\n",
    "# DATAPATH = '/sharedData/scratch/'\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "#import os.path as op\n",
    "from os import path as op\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import xarray as xr\n",
    "import netCDF4\n",
    "from pathlib import Path\n",
    "from subprocess import Popen\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = Path('../storage/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for unfiltered cloud mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rad2BT(rad, planck_fk1, planck_fk2, planck_bc1, planck_bc2):\n",
    "    \"\"\"Radiances to Brightness Temprature (using black body equation)\"\"\"\n",
    "    invRad = np.array(rad)**(-1)\n",
    "    arg = (invRad*planck_fk1) + 1.0\n",
    "    T = (- planck_bc1+(planck_fk2 * (np.log(arg)**(-1))) )*(1/planck_bc2) \n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createUnfilteredPlotArray(ncFile,npFile,npPath):#Filtered Histrogram for cloud clear sky mask\n",
    "    Tmean= []\n",
    "    times = []\n",
    "    for ncf, npf in zip(ncFile, npFile):\n",
    "        imageBox = np.load(op.join(npPath,npf))\n",
    "        myFile = xr.open_dataset(op.join(ncPath,ncf))\n",
    "        planck_fk1 = float(myFile['planck_fk1'].data)\n",
    "        planck_fk2 = float(myFile['planck_fk2'].data) \n",
    "        planck_bc1 = float(myFile['planck_bc1'].data)                       \n",
    "        planck_bc2 = float(myFile['planck_bc2'].data)     \n",
    "        T = Rad2BT(imageBox.mean(), planck_fk1, planck_fk2, planck_bc1, planck_bc2)\n",
    "        tString = ncf[31:38]\n",
    "        times.append(tString)\n",
    "        Tmean.append(T)\n",
    "    return times, Tmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listurls(prefix,html):\n",
    "    from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(html.text)\n",
    "    urllist = [elt['href'] for elt in soup.find_all(href=re.compile(prefix))]\n",
    "    return urllist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nc_Numpy(ncFile, pathOut):\n",
    "    myFile = xr.open_dataset(ncFile)\n",
    "    dat = myFile.metpy.parse_cf('Rad')\n",
    "    geos = dat.metpy.cartopy_crs\n",
    "\n",
    "    cartopy_extent_goes = geos.x_limits + geos.y_limits\n",
    "    pyresample_extent_goes = (cartopy_extent_goes[0],\n",
    "                                cartopy_extent_goes[2],\n",
    "                                cartopy_extent_goes[1],\n",
    "                                cartopy_extent_goes[3])\n",
    "    goes_params = geos.proj4_params\n",
    "    rad = dat.data\n",
    "    \n",
    "    def normIm(im,gamma=1.0,reverse=False):\n",
    "        nim = ((im-np.nanmin(im))*(np.nanmax(im)-np.nanmin(im))**(-1))\n",
    "        if reverse:#want clouds to be white\n",
    "            nim = (1.0-nim**(gamma))\n",
    "        return nim\n",
    "    \n",
    "    def goes_2_roi(geos_crs, \n",
    "               target_extent,\n",
    "               target_rows,#actual length or base\n",
    "               target_cols,#actual width or height\n",
    "               cartopy_target_proj,\n",
    "               data_key='Rad',\n",
    "               radius_of_influence=50000):\n",
    "        \"\"\"Function that goes from loaded GOES data to data resampled in a projection for an extent\"\"\"\n",
    "        cartopy_source_extent = geos_crs.x_limits + geos_crs.y_limits\n",
    "        pyresample_source_extent = (cartopy_source_extent[0],\n",
    "                                    cartopy_source_extent[2],\n",
    "                                    cartopy_source_extent[1],\n",
    "                                    cartopy_source_extent[3])\n",
    "        rad = dat.data\n",
    "        source_area = geometry.AreaDefinition('GOES-1X', 'Full Disk','GOES-1X', \n",
    "                                              geos_crs.proj4_params,\n",
    "                                              rad.shape[1], rad.shape[0],\n",
    "                                              pyresample_source_extent)\n",
    "        area_target_def = geometry.AreaDefinition('areaTest', 'Target Region', 'areaTest',\n",
    "                                            cartopy_target_proj.proj4_params,\n",
    "                                            target_rows, target_cols,\n",
    "                                            target_extent)\n",
    "        geos_con_nn = image.ImageContainerNearest(rad, \n",
    "                                                source_area, \n",
    "                                                radius_of_influence=radius_of_influence)\n",
    "\n",
    "        # Here we are using pyresample for the remapping\n",
    "        area_proj_con_nn = geos_con_nn.resample(area_target_def)\n",
    "        return area_proj_con_nn.image_data\n",
    "        \n",
    "    def cartopy_pyresample_toggle_extent(input_extent):\n",
    "        return np.array(input_extent)[np.array([0,2,1,3])]\n",
    "\n",
    "    def transform_cartopy_extent(source_extent,source_proj, target_proj):\n",
    "        target_extent = target_proj.transform_points(source_proj, \n",
    "                                                     np.array(source_extent[:2]),\n",
    "                                                     np.array(source_extent[2:])).ravel()\n",
    "        # target_extent in 3D, must be in 2D\n",
    "        return cartopy_pyresample_toggle_extent(np.array(target_extent)[np.array([0,1,3,4])])\n",
    "    pc = ccrs.PlateCarree()\n",
    "    mc = ccrs.Mercator()\n",
    "\n",
    "    # Convert extent from pc to mc (both cylindrical projections)\n",
    "    extent_pc = [-109.59326, -102.40674, 8.94659, -8.94656]\n",
    "    \n",
    "    target_extent_mc_cartopy = transform_cartopy_extent(extent_pc, pc, mc)\n",
    "    target_extent_mc_pyresample = cartopy_pyresample_toggle_extent(target_extent_mc_cartopy)\n",
    "    \n",
    "    roi_rads = goes_2_roi(geos,\n",
    "               target_extent_mc_pyresample,\n",
    "               401,1001,\n",
    "               mc)\n",
    "    ####\n",
    "    full_filename = op.join(pathOut,ncFile[:-3])\n",
    "    np.save(full_filename,roi_rads)\n",
    "    myFile.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(filename,toPath, saveName):\n",
    "    with open(filename, 'r') as fid:\n",
    "        txt = fid.read()\n",
    "    urls = txt.split()\n",
    "    cmdlist = [ 'wget ' + url +' -P ' + toPath for url in urls +' -O '+ saveName]#if re.search('C07',url)\n",
    "    print(len(urls),len(list(set(urls))),len(cmdlist))\n",
    "\n",
    "    for url, cmd in zip(urls, cmdlist):\n",
    "        print(cmd)\n",
    "        if op.exists(url):\n",
    "            continue\n",
    "        pid = Popen(cmd, shell=True)\n",
    "        pid.communicate()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "templateURL = 'http://home.chpc.utah.edu/~u0553130/Brian_Blaylock/cgi-bin/'   \\\n",
    "    + 'goes16_download.cgi?source=aws&satellite=' \\\n",
    "    + 'noaa-goes{SS}&domain=F&product=ABI-L1b-Rad&date=20{yy}-{mm}-{dd}&hour={hr}'\n",
    "Sat = 16\n",
    "band = 8\n",
    "year = 2020\n",
    "month = 1\n",
    "day = 1\n",
    "hour = 0\n",
    "\n",
    "\n",
    "search = itertools.product([Sat], [band], [year], [month], [day], [hour])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for GOES-16 and GOES-17 and plot what is available\n",
    "for SS, bb, yy, mm, dd, hr in search:\n",
    "    SS, bb, yy, mm, dd, hr =        \n",
    "        str(SS).zfill(2),\n",
    "        str(bb).zfill(2),\n",
    "        str(yy).zfill(4),\n",
    "        str(mm).zfill(2),\n",
    "        str(dd).zfill(2),\n",
    "        str(hr).zfill(2)\n",
    "        \n",
    "    '''Get URLS for download'''    \n",
    "    req16 = requests.get(templateURL)\n",
    "    SS = '17'\n",
    "    req17 = requests.get(templateURL)\n",
    "    if yy == '2018':\n",
    "        product = '3'\n",
    "    else:\n",
    "        product = '6'\n",
    "    prefix = f\"OR_ABI-L1b-RadF-M{product}C\" + bb\n",
    "    prefix.format(**{'product':product})\n",
    "    bandURLList16 = listurls(prefix,req16)#list of strings using beautiful soup\n",
    "    bandURLList17 = listurls(prefix,req17)\n",
    "    bandURLList16.sort()\n",
    "    bandURLList17.sort()\n",
    "    \n",
    "    cnt = 0 #keep a counter to avoid crossing FD with similar file names and performance\n",
    "    '''iterate over pairs of GOES NETCDF, download, and convert to numpy'''\n",
    "    for i, FD16 in enumerate(req16): #Last string chars are of this format: c20192220009464.nc\n",
    "        cYYYYDDDHHt = FD[-18:-9]\n",
    "        for FD17 in req17[cnt:i]:\n",
    "            if FD16[-18:-9] == FD17[-18:-9]:\n",
    "                cnt +=1\n",
    "                f17 = open(FD17,'w')\n",
    "                download(op.join('buffer', f17),'buffer','nc17')\n",
    "                npy17 = create_nc_Numpy(op.join('buffer', 'nc17'), 'buffer')\n",
    "                f17.close()\n",
    "                #break\n",
    "            f16 = open(FD17,'w')\n",
    "            download(op.join('buffer', f16),'buffer','nc16')\n",
    "            npy16 = create_nc_Numpy(op.join('buffer', 'nc16'), 'buffer')\n",
    "            f16.close()\n",
    " \n",
    "        '''Create subplot figures and save'''\n",
    "        fig, (ax1, ax2, ax3, ax4) = plt.subplots(2, 2)\n",
    "        \n",
    "        '''Histograms'''\n",
    "#         ax.set_title(f'{hh}:{mm}')\n",
    "#                 ax.set_ylabel('density (unitless)',fontsize = 16)\n",
    "#                 ax.set_xlabel('Temperature (K)', fontsize = 16)\n",
    "\n",
    "#                 Tbox = Rad2BT(imageBox, planck_fk1, planck_fk2, planck_bc1, planck_bc2)\n",
    "#                 ax.hist(Tbox.ravel(), bins = bins, density = True, label = 'Temp dist.')\n",
    "#                 #ax.plot([T,T], [0,0.3],'r', label = 'something')\n",
    "#                 ax.axvline(T, color='r',label = 'NOAA avg.')\n",
    "#             axes[0].legend(loc='upper left')\n",
    "#         fig.savefig('..'+ op.join(DATAPATH,f\"Histograms_filtered/G_{SS}_04-{str(8+dd).zfill(2)}-2019\"))\n",
    "        \n",
    "        '''ECDF'''\n",
    "        \n",
    "        '''AUC'''\n",
    "        \n",
    "#     times17, mean17 = getTmean('17', npPath, band, day)\n",
    "#     times16, mean16 = getTmean('16', npPath, band, day)\n",
    "\n",
    "#     ptimes17 = [datetime.strptime(f\"2019{t}\", \"%Y%j%H%M\") for t in times17]\n",
    "#     ptimes16 = [datetime.strptime(f\"2019{t}\", \"%Y%j%H%M\") for t in times16]\n",
    "#     fig, ax1 = plt.subplots(figsize=(15,5))#constrained_layout=False\n",
    "#     _ = ax1.plot_date(ptimes17, mean17 , label=\"GOES-17\", color='tab:red', marker='+', markersize = 16)\n",
    "#     _ = ax1.plot_date(ptimes16, mean16 , label='GOES-16', color='tab:blue', marker='+', markersize = 16, zorder=-1)\n",
    "#     _ = ax1.set_ylim(220,260)\n",
    "#     _ = ax1.tick_params('both', labelsize=18)\n",
    "#     _ = ax1.legend()\n",
    "#     _ = ax1.set_title(f'Mean Temperatures (K) for a 401 x 1001 Portion\\n of Band 08 on 04-{str(8+j)}-2019', fontweight ='bold', fontsize = 22)\n",
    "#     _ = ax1.set_ylabel('Temperature (K)',fontsize = 16)\n",
    "#     _ = ax1.set_xlabel('time (hours)',fontsize = 16)\n",
    "#     _ = ax1.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "\n",
    "\n",
    "#     _ = plt.savefig('..'+ op.join(DATAPATH,f\"Mean_temp_unfiltered/04-{str(8+j).zfill(2)}-2019\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'c20192220009464.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c20192220'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string[-18:-9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c20192220009464.nc'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
