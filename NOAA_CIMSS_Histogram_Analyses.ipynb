{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram of GOES-16, GOES-17, Empirical CDF, and AUC for Full disk samples in region of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import urllib.request\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import itertools\n",
    "import pandas as pd\n",
    "# npPath = '/sharedData/scratch/all_npy3/'\n",
    "# ncPath = '/sharedData/scratch/april_data/'\n",
    "# acmPath = '/sharedData/scratch/all_npy3/'\n",
    "# DATAPATH = '/sharedData/scratch/'\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "#import os.path as op\n",
    "from os import path as op\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# %matplotlib agg\n",
    "# %matplotlib agg\n",
    "import xarray as xr\n",
    "import metpy\n",
    "import cartopy.crs as ccrs\n",
    "from pyresample import image, geometry\n",
    "import seaborn as sns #ref\n",
    "import netCDF4\n",
    "sns.set(style=\"darkgrid\")\n",
    "from pathlib import Path\n",
    "from subprocess import Popen\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = Path('../storage/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for unfiltered cloud mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rad2BT(rad, planck_fk1, planck_fk2, planck_bc1, planck_bc2):\n",
    "    \"\"\"Radiances to Brightness Temprature (using black body equation)\"\"\"\n",
    "    invRad = np.array(rad)**(-1)\n",
    "    arg = (invRad*planck_fk1) + 1.0\n",
    "    T = (- planck_bc1+(planck_fk2 * (np.log(arg)**(-1))) )*(1/planck_bc2) \n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createUnfilteredPlotArray(ncFile,npFile,npPath):#Filtered Histrogram for cloud clear sky mask\n",
    "    Tmean= []\n",
    "    times = []\n",
    "    for ncf, npf in zip(ncFile, npFile):\n",
    "        imageBox = np.load(op.join(npPath,npf))\n",
    "        myFile = xr.open_dataset(op.join(ncPath,ncf))\n",
    "        planck_fk1 = float(myFile['planck_fk1'].data)\n",
    "        planck_fk2 = float(myFile['planck_fk2'].data) \n",
    "        planck_bc1 = float(myFile['planck_bc1'].data)                       \n",
    "        planck_bc2 = float(myFile['planck_bc2'].data)     \n",
    "        T = Rad2BT(imageBox.mean(), planck_fk1, planck_fk2, planck_bc1, planck_bc2)\n",
    "        tString = ncf[31:38]\n",
    "        times.append(tString)\n",
    "        Tmean.append(T)\n",
    "    return times, Tmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listurls(prefix,html):\n",
    "    from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(html.text)\n",
    "    urllist = [elt['href'] for elt in soup.find_all(href=re.compile(prefix))]\n",
    "    return urllist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nc_Numpy(ncFile, pathOut):\n",
    "    myFile = xr.open_dataset(ncFile,engine=\"netcdf4\")\n",
    "    dat = myFile.metpy.parse_cf('Rad')#myFile['Rad']\n",
    "    geos = dat.metpy.cartopy_crs\n",
    "\n",
    "    cartopy_extent_goes = geos.x_limits + geos.y_limits\n",
    "    pyresample_extent_goes = (cartopy_extent_goes[0],\n",
    "                                cartopy_extent_goes[2],\n",
    "                                cartopy_extent_goes[1],\n",
    "                                cartopy_extent_goes[3])\n",
    "    goes_params = geos.proj4_params\n",
    "    rad = dat.data\n",
    "    \n",
    "    def normIm(im,gamma=1.0,reverse=False):\n",
    "        nim = ((im-np.nanmin(im))*(np.nanmax(im)-np.nanmin(im))**(-1))\n",
    "        if reverse:#want clouds to be white\n",
    "            nim = (1.0-nim**(gamma))\n",
    "        return nim\n",
    "    \n",
    "    def goes_2_roi(geos_crs, \n",
    "               target_extent,\n",
    "               target_rows,#actual length or base\n",
    "               target_cols,#actual width or height\n",
    "               cartopy_target_proj,\n",
    "               data_key='Rad',\n",
    "               radius_of_influence=50000):\n",
    "        \"\"\"Function that goes from loaded GOES data to data resampled in a projection for an extent\"\"\"\n",
    "        cartopy_source_extent = geos_crs.x_limits + geos_crs.y_limits\n",
    "        pyresample_source_extent = (cartopy_source_extent[0],\n",
    "                                    cartopy_source_extent[2],\n",
    "                                    cartopy_source_extent[1],\n",
    "                                    cartopy_source_extent[3])\n",
    "        rad = dat.data\n",
    "        source_area = geometry.AreaDefinition('GOES-1X', 'Full Disk','GOES-1X', \n",
    "                                              geos_crs.proj4_params,\n",
    "                                              rad.shape[1], rad.shape[0],\n",
    "                                              pyresample_source_extent)\n",
    "        area_target_def = geometry.AreaDefinition('areaTest', 'Target Region', 'areaTest',\n",
    "                                            cartopy_target_proj.proj4_params,\n",
    "                                            target_rows, target_cols,\n",
    "                                            target_extent)\n",
    "        geos_con_nn = image.ImageContainerNearest(rad, \n",
    "                                                source_area, \n",
    "                                                radius_of_influence=radius_of_influence)\n",
    "\n",
    "        # Here we are using pyresample for the remapping\n",
    "        area_proj_con_nn = geos_con_nn.resample(area_target_def)\n",
    "        return area_proj_con_nn.image_data\n",
    "        \n",
    "    def cartopy_pyresample_toggle_extent(input_extent):\n",
    "        return np.array(input_extent)[np.array([0,2,1,3])]\n",
    "\n",
    "    def transform_cartopy_extent(source_extent,source_proj, target_proj):\n",
    "        target_extent = target_proj.transform_points(source_proj, \n",
    "                                                     np.array(source_extent[:2]),\n",
    "                                                     np.array(source_extent[2:])).ravel()\n",
    "        # target_extent in 3D, must be in 2D\n",
    "        return cartopy_pyresample_toggle_extent(np.array(target_extent)[np.array([0,1,3,4])])\n",
    "    pc = ccrs.PlateCarree()\n",
    "    mc = ccrs.Mercator()\n",
    "\n",
    "    # Convert extent from pc to mc (both cylindrical projections)\n",
    "    extent_pc = [-109.59326, -102.40674, 8.94659, -8.94656]\n",
    "    \n",
    "    target_extent_mc_cartopy = transform_cartopy_extent(extent_pc, pc, mc)\n",
    "    target_extent_mc_pyresample = cartopy_pyresample_toggle_extent(target_extent_mc_cartopy)\n",
    "    \n",
    "    roi_rads = goes_2_roi(geos,\n",
    "               target_extent_mc_pyresample,\n",
    "               401,1001,\n",
    "               mc)\n",
    "    ####\n",
    "    full_filename = op.join(pathOut,ncFile[:-3])\n",
    "    np.save(full_filename,roi_rads)\n",
    "    myFile.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url,toPath, saveName):\n",
    "    cmd = [ 'wget ' + url +' -P ' + toPath +' -O '+ saveName]#if re.search('C07',url)\n",
    "    print(cmd)\n",
    "    pid = Popen(cmd, shell=True)\n",
    "    pid.communicate()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sat = 16\n",
    "band = 8\n",
    "year = 2020\n",
    "month = 1\n",
    "day = 1\n",
    "hour = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'https://noaa-goes16.s3.amazonaws.com/ABI-L1b-RadF/2020/001/00/OR_ABI-L1b-RadF-M6C08_G16_s20200010000216_e20200010009524_c20200010010002.nc'), (1, 'https://noaa-goes16.s3.amazonaws.com/ABI-L1b-RadF/2020/001/00/OR_ABI-L1b-RadF-M6C08_G16_s20200010010216_e20200010019524_c20200010019593.nc'), (2, 'https://noaa-goes16.s3.amazonaws.com/ABI-L1b-RadF/2020/001/00/OR_ABI-L1b-RadF-M6C08_G16_s20200010020216_e20200010029524_c20200010029599.nc'), (3, 'https://noaa-goes16.s3.amazonaws.com/ABI-L1b-RadF/2020/001/00/OR_ABI-L1b-RadF-M6C08_G16_s20200010030216_e20200010039524_c20200010040002.nc'), (4, 'https://noaa-goes16.s3.amazonaws.com/ABI-L1b-RadF/2020/001/00/OR_ABI-L1b-RadF-M6C08_G16_s20200010040216_e20200010049524_c20200010049598.nc'), (5, 'https://noaa-goes16.s3.amazonaws.com/ABI-L1b-RadF/2020/001/00/OR_ABI-L1b-RadF-M6C08_G16_s20200010050216_e20200010059524_c20200010059599.nc')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/adomakor412/conda/envs/MyEnv/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in log\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "search = itertools.product([Sat], [band], [year], [month], [day], [hour])\n",
    "bins = np.linspace(220,250,101)\n",
    "log = open('log_Histogram.txt','w')\n",
    "\n",
    "#check for GOES-16 and GOES-17 and plot what is available\n",
    "for SS, bb, yyyy, mm, dd, hr in search:\n",
    "    SS, bb, yyyy, mm, dd, hr = \\\n",
    "        str(SS).zfill(2),\\\n",
    "        str(bb).zfill(2),\\\n",
    "        str(yyyy).zfill(4),\\\n",
    "        str(mm).zfill(2),\\\n",
    "        str(dd).zfill(2),\\\n",
    "        str(hr).zfill(2)\n",
    "    templateURL = f'http://home.chpc.utah.edu/~u0553130/Brian_Blaylock/cgi-bin/'\\\n",
    "    + f'goes16_download.cgi?source=aws&satellite='\\\n",
    "    + f'noaa-goes{SS}&domain=F&product=ABI-L1b-Rad&date={yyyy}-{mm}-{dd}&hour={hr}'\n",
    "    \n",
    "    '''Get URLS for download'''\n",
    "    req16 = requests.get(templateURL)\n",
    "   \n",
    "    SS = '17'\n",
    "    req17 = requests.get(templateURL)\n",
    "    \n",
    "    if yyyy == '2018':\n",
    "        product = '3'\n",
    "    else:\n",
    "        product = '6'\n",
    "    prefix = f\"OR_ABI-L1b-RadF-M{product}C\" + bb\n",
    "    prefix.format(**{'product':product})\n",
    "    bandURLList16 = listurls(prefix,req16)#list of strings using beautiful soup\n",
    "    bandURLList17 = listurls(prefix,req17)\n",
    "    bandURLList16.sort()\n",
    "    bandURLList17.sort()\n",
    "    \n",
    "    cnt = 0 #keep a counter to avoid crossing FD with similar file names and performance\n",
    "    '''iterate over pairs of GOES NETCDF, download, and convert to numpy'''\n",
    "    print(list(enumerate(bandURLList16)))\n",
    "    for i, FD16 in enumerate(bandURLList16): #Last string chars are of this format: c20192220009464.nc   \n",
    "        print(str(FD16), file=log)        \n",
    "        cYYYYDDDHHt = FD16[-18:-7]\n",
    "        t = FD16[-7]\n",
    "        _FD17 = None\n",
    "        for FD17 in bandURLList17[cnt:i]:\n",
    "            if cYYYYDDDHHt == FD17[-18:-7]:\n",
    "                cnt +=1\n",
    "                _FD17 = FD17\n",
    "                download17 = requests.get(FD17)\n",
    "                nc17 = open('nc17.nc','wb')\n",
    "                nc17.write(download17.content)\n",
    "                nc17.close()\n",
    "                npy17 = create_nc_Numpy('nc17.nc', '.')\n",
    "                \n",
    "                '''Load numpy files'''\n",
    "                imageBox_17 = np.load('nc17.npy')\n",
    "                myFile_17 = xr.open_dataset('nc17.nc')\n",
    "                planck_fk1_17 = float(myFile_17['planck_fk1'].data)\n",
    "                planck_fk2_17 = float(myFile_17['planck_fk2'].data) \n",
    "                planck_bc1_17 = float(myFile_17['planck_bc1'].data)                       \n",
    "                planck_bc2_17 = float(myFile_17['planck_bc2'].data)\n",
    "                break\n",
    "            else:\n",
    "                _FD17 = None\n",
    "                imageBox_17 = None\n",
    "                planck_fk1_17 = None\n",
    "                planck_fk2_17 = None\n",
    "                planck_bc1_17 = None\n",
    "                planck_bc2_17 = None\n",
    "        download16 = requests.get(FD16)\n",
    "        nc16 = open('nc16.nc','wb')\n",
    "        nc16.write(download16.content)\n",
    "        nc16.close()\n",
    "        npy16 = create_nc_Numpy('nc16.nc', '.')\n",
    "\n",
    "        '''Load numpy files'''\n",
    "        imageBox_16 = np.load('nc16.npy')\n",
    "        myFile_16 = xr.open_dataset('nc16.nc')\n",
    "        planck_fk1_16 = float(myFile_16['planck_fk1'].data)\n",
    "        planck_fk2_16 = float(myFile_16['planck_fk2'].data) \n",
    "        planck_bc1_16 = float(myFile_16['planck_bc1'].data)                       \n",
    "        planck_bc2_16 = float(myFile_16['planck_bc2'].data)\n",
    " \n",
    "        '''Create subplot figures and save'''\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2,figsize=(15,15))\n",
    "        \n",
    "        '''Histograms'''\n",
    "        ax1.set_title(f'GOES-16 ABI Band {bb} Day {mm}-{dd} {hr}:{t}0')\n",
    "        ax1.set_ylabel('density (unitless)',fontsize = 16)\n",
    "        ax1.set_xlabel('Temperature (K)', fontsize = 16)\n",
    "        Tbox16 = Rad2BT(imageBox_16, planck_fk1_16, planck_fk2_16, planck_bc1_16, planck_bc2_16)\n",
    "        ax1.hist(Tbox16.ravel(), bins = bins, density = True, label = 'Temp dist.')\n",
    "        ax1.axvline(Tbox16.mean(), color='r',label = 'NOAA avg.')\n",
    "        ax1.legend(loc='upper left')\n",
    "        \n",
    "        if None != _FD17:\n",
    "            ax2.set_title(f'GOES-17 ABI Band {bb} Day {mm}-{dd} {hr}:{t}0')\n",
    "            ax2.set_ylabel('density (unitless)',fontsize = 16)\n",
    "            ax2.set_xlabel('Temperature (K)', fontsize = 16)\n",
    "            Tbox17 = Rad2BT(imageBox_17, planck_fk1_17, planck_fk2_17, planck_bc1_17, planck_bc2_17)\n",
    "            ax2.hist(Tbox17.ravel(), bins = bins, density = True, label = 'Temp dist.')\n",
    "            ax2.axvline(Tbox17.mean(), color='r',label = 'NOAA avg.')\n",
    "            ax2.legend(loc='upper left')\n",
    "            \n",
    "            rc = np.vstack([Tbox16.ravel(), Tbox17.ravel()])\n",
    "            XY = rc[:,np.isfinite(rc).all(axis=0)]\n",
    "            G16 = XY[0]\n",
    "            G17 = XY[1]\n",
    "            plabels = ['0%', '25%', '50%', '75%', '100%']\n",
    "            \n",
    "            '''ECDF'''\n",
    "            xticks = np.arange(len(G17))\n",
    "            xticks = [st.scoreatpercentile(xticks, p) for p in [0, 25, 50, 75, 100]]\n",
    "            ax3.plot(sorted(G17), label='G17')\n",
    "            ax3.plot(sorted(G16), label='G16')\n",
    "            ax3.legend(loc = 'upper left')\n",
    "            ax3.set_title(f'Empirical CDF for Apr-{day}-2019')\n",
    "            ax3.set_xticks(xticks)\n",
    "            ax3.set_xticklabels(plabels)\n",
    "            ax3.set_xlabel('quantiles')\n",
    "            ax3.set_ylabel('Temperature')\n",
    "\n",
    "            '''AUC'''\n",
    "            _G17 = np.linspace(G17.min(), G17.max(), 1000)\n",
    "            B = [st.scoreatpercentile(G16, st.percentileofscore(G17,g17s,\n",
    "                kind='strict')) for g17s in _G17]\n",
    "\n",
    "            _B = (B - min(B))/(max(B) - min(B))\n",
    "            _G17n = (_G17 - min(_G17))/(max(_G17) - min(_G17))\n",
    "\n",
    "            AUC = round(sum(_B)/1000,5)\n",
    "            #chart[ts] = AUC\n",
    "            \n",
    "            ax4.plot(_G17n,_B, label=f\"AUC: {AUC}\")\n",
    "            ax4.set_ylabel('G16')\n",
    "            ax4.set_xlabel('G17')\n",
    "            ax4.set_title('Transform of G17 to G16')\n",
    "            ax4.set_aspect('equal')\n",
    "            ax4.legend(loc = 'upper left')\n",
    "        \n",
    "        #ax.plot([T,T], [0,0.3],'r', label = 'something')\n",
    "        YYYY = FD16[-17:-13]\n",
    "        DDD = FD16[-13:-10]\n",
    "        HH = FD16[-10:-8]\n",
    "        i = FD16.find('_s')\n",
    "        MM = FD16[i+8: i+10]\n",
    "        fig.savefig(op.join(storage,f\"GOES-R_panel_GOES16vsGOES17_FD_{YYYY}{DDD}{HH}{MM}_Band{bb}.png\"));\n",
    "        plt.close()\n",
    "        #GOES17_FPMTemp_GOES16vsGOES17MeanDiff_FD_2020357_000032_Band08.png\n",
    "#     times17, mean17 = getTmean('17', npPath, band, day)\n",
    "#     times16, mean16 = getTmean('16', npPath, band, day)\n",
    "\n",
    "#     ptimes17 = [datetime.strptime(f\"2019{t}\", \"%Y%j%H%M\") for t in times17]\n",
    "#     ptimes16 = [datetime.strptime(f\"2019{t}\", \"%Y%j%H%M\") for t in times16]\n",
    "#     fig, ax1 = plt.subplots(figsize=(15,5))#constrained_layout=False\n",
    "#     _ = ax1.plot_date(ptimes17, mean17 , label=\"GOES-17\", color='tab:red', marker='+', markersize = 16)\n",
    "#     _ = ax1.plot_date(ptimes16, mean16 , label='GOES-16', color='tab:blue', marker='+', markersize = 16, zorder=-1)\n",
    "#     _ = ax1.set_ylim(220,260)\n",
    "#     _ = ax1.tick_params('both', labelsize=18)\n",
    "#     _ = ax1.legend()\n",
    "#     _ = ax1.set_title(f'Mean Temperatures (K) for a 401 x 1001 Portion\\n of Band 08 on 04-{str(8+j)}-2019', fontweight ='bold', fontsize = 22)\n",
    "#     _ = ax1.set_ylabel('Temperature (K)',fontsize = 16)\n",
    "#     _ = ax1.set_xlabel('time (hours)',fontsize = 16)\n",
    "#     _ = ax1.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "\n",
    "\n",
    "#     _ = plt.savefig('..'+ op.join(DATAPATH,f\"Mean_temp_unfiltered/04-{str(8+j).zfill(2)}-2019\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
