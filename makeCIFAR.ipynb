{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "maritime-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "#import numpy as np\n",
    "import os\n",
    "\n",
    "__author__ = \"Andres Vourakis\"\n",
    "__email__ = \"andresvourakis@gmail.com\"\n",
    "__license__ = \"GPL\"\n",
    "__data__ = \"May 25, 2017\"\n",
    "\n",
    "\n",
    "def image_to_byte_array(image, class_index, size):\n",
    "\n",
    "    img = Image.open(image)\n",
    "    \n",
    "    #Resize\n",
    "    img = img.resize(size) #TODO Check if resizing to given dim can be done\n",
    "\n",
    "    #Convert image to 3 dimensional array\n",
    "    img_array = np.array(img)\n",
    "\n",
    "    #Convert 3 dimensional array into row major order\n",
    "    img_array_R = img_array[:,:,0].flatten()\n",
    "    img_array_G = img_array[:,:,1].flatten()\n",
    "    img_array_B = img_array[:,:,2].flatten()\n",
    "    class_index = [class_index]\n",
    "\n",
    "    # Turn row-major array into bytes\n",
    "    #img_byte_array = np.concatenate((img_array_R, img_array_G, img_array_B)).tobytes() #Turn into row-major byte array\n",
    "    img_byte_array = np.array(list(class_index) + list(img_array_R) + list(img_array_G) + list(img_array_B), np.uint8) #Turn into row-major byte array\n",
    "    \n",
    "    return img_byte_array\n",
    "\n",
    "def create_meta_data(class_labels, destination):\n",
    "    \n",
    "    '''\n",
    "        TODO: Check if directory exists\n",
    "    '''\n",
    "    \n",
    "    file_name = 'batches_meta.txt'\n",
    "    file_path = os.path.join(destination, file_name)\n",
    "    with open(file_path, 'w') as file:\n",
    "        for label in class_labels:\n",
    "            file.write(str(label) + '\\n')\n",
    "\n",
    "\n",
    "def label_to_index(class_labels, class_label):\n",
    "    return class_labels.index(class_label)\n",
    "\n",
    "def open_batch(destination,CURRENT_BATCH):\n",
    "    file_name = 'data_batch_' + str(CURRENT_BATCH) + '.bin'\n",
    "    file_path = os.path.join(destination, file_name)\n",
    "    return open(file_path, 'wb')\n",
    "\n",
    "def close_batch(file):\n",
    "    file.close()\n",
    "\n",
    "def process_image_dataset(source, destination, size = (32, 32), batch = 1):\n",
    "    \"\"\" \n",
    "        Processes dataset into binary version of CIFAR-10 dataset\n",
    "\n",
    "    Args:\n",
    "        source: Abosulute path to directory containing subdirectories of image datasets.\n",
    "        destination: Absolute path of directory where to save process image datasets.\n",
    "        size (default = (32,32)): square dimensions (width and height) to resize images\n",
    "        batch (default = 1): Number of batches to divide image dataset.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    class_labels = next(os.walk(source))[1]\n",
    "    #dataset_size = len(next(os.walk(source))[2]) #Only gives tot number of files in current directory\n",
    "\n",
    "    dataset_size = 0\n",
    "\n",
    "    for root, subdirs, files in os.walk(source):\n",
    "        dataset_size += len(files) #TODO: Find more efficient way of getting tot num of files\n",
    "    \n",
    "   \n",
    "    batch_size = dataset_size / batch # Total number of images per batch\n",
    "    REACHED_BATCH_MAX = False\n",
    "    CURRENT_BATCH = 1\n",
    "\n",
    "    #create meta data file\n",
    "    create_meta_data(class_labels, destination) #TODO: Check time complex. \n",
    "    batch = open_batch(destination,CURRENT_BATCH)\n",
    "\n",
    "    #load data and output data\n",
    "    for root, subdirs, files in os.walk(source):\n",
    "\n",
    "        class_label = os.path.relpath(root, source) \n",
    "\n",
    "        if(class_label != '.'): # Ignore source directory\n",
    "\n",
    "            class_index = label_to_index(class_labels, class_label) # class index in bytes\n",
    "             \n",
    "            #data = np.array([image_to_byte_array(os.path.join(root, file), size) for file in files]) #Turn images to numpy array and save into data array\n",
    "            for counter, file in enumerate(files):\n",
    "                \n",
    "                if(REACHED_BATCH_MAX):\n",
    "                    #open new batch and increment CURRENT_BATCH\n",
    "                    CURRENT_BATCH += 1\n",
    "                    batch = open_batch(destination)\n",
    "    \n",
    "                file_path = os.path.join(root, file)\n",
    "                image_byte_array = image_to_byte_array(file_path, class_index, size)\n",
    "                \n",
    "                #write to file while max batch size hasnt been reached!\n",
    "                batch.write(image_byte_array)\n",
    "                \n",
    "                if(counter == batch_size):\n",
    "                    #close current batch and set REACHED_MAX_BATCH to TRUE\n",
    "                    close_batch(batch)\n",
    "                    REACHED_BATCH_MAX = True\n",
    "                        \n",
    "\n",
    "    close_batch(batch) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sustained-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from dataset_to_cifar import process_dataset\n",
    "\n",
    "\n",
    "# Set square dimensions of images\n",
    "size = (5424,5424) # 32 by 32 pixels\n",
    "\n",
    "# Set number of batches\n",
    "batch = 1\n",
    "\n",
    "# Source of image dataset (Use absolute path)\n",
    "source = '/home/radomako/train_set_color/sharkfin/'\n",
    "\n",
    "# Destination of processed dataset (use absolute path)\n",
    "destination = 'myData'\n",
    "\n",
    "# Process dataset\n",
    "process_image_dataset(source, destination, size, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-power",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
